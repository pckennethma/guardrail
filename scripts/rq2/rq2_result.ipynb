{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "dataset_name_ls = [\n",
    "    \"adult\",\n",
    "    \"lung_cancer\",\n",
    "    \"cylinder-bands\",\n",
    "    \"diabetes\",\n",
    "    \"contraceptive\",\n",
    "    \"blood-transfusion-service-center\",\n",
    "    \"steel-plates-fault\",\n",
    "    \"jungle_chess_2pcs_raw_endgame_complete\",\n",
    "    \"telco_customer_churn\",\n",
    "    \"bank-marketing\",\n",
    "    \"PhishingWebsites\",\n",
    "    \"hotel_bookings\",\n",
    "]\n",
    "mode_ls = [\"gt\", \"ignore\", \"coerce\", \"rectify\"]\n",
    "sql_ls = [\"q1.sql\", \"q2.sql\", \"q3.sql\", \"q4.sql\"]\n",
    "\n",
    "result_dict_full = {}  # dataset_name -> mode-> result\n",
    "for dataset_name in dataset_name_ls:\n",
    "    with open(f\"../example_query/{dataset_name}/rq2_result.json\", \"r\") as f:\n",
    "        rq2_result = json.load(f)\n",
    "    result_dict = {}\n",
    "    possible_invalid_keys = {}\n",
    "    for mode in mode_ls:\n",
    "        result = []\n",
    "        for sql_name in sql_ls:\n",
    "            gt_result = np.array(rq2_result[sql_name + \",gt\"])\n",
    "            cur_result = np.array(rq2_result[sql_name + \",\" + mode])\n",
    "            if gt_result.shape[0] != cur_result.shape[0]:\n",
    "                if gt_result.shape[1] > 2:\n",
    "                    print(\"error\")\n",
    "                    print(dataset_name, mode, sql_name)\n",
    "                if mode == \"coerce\":\n",
    "                    vaild_result = np.zeros(gt_result.shape[0])\n",
    "                    for i in range(len(cur_result)):\n",
    "                        print(np.where(gt_result[:, 0] == cur_result[i][0]))\n",
    "                        row_index = np.where(gt_result[:, 0] == cur_result[i][0])[0][0]\n",
    "                        vaild_result[row_index] = cur_result[i][1]\n",
    "                    result.extend(vaild_result.astype(float))\n",
    "                else:\n",
    "                    print(\"error\")\n",
    "                    print(dataset_name, mode, sql_name)\n",
    "            else:\n",
    "                if gt_result.shape[1] > 1:\n",
    "                    if not np.array_equal(gt_result[:, 0], cur_result[:, 0]):\n",
    "                        print(\"error\")\n",
    "                        print(dataset_name, mode, sql_name)\n",
    "                        vaild_result = np.zeros(gt_result.shape[0])\n",
    "                        for i in range(len(cur_result)):\n",
    "                            invalid_idx = 0\n",
    "                            if cur_result[i][0] in gt_result[:, 0]:\n",
    "                                row_index = np.where(\n",
    "                                    gt_result[:, 0] == cur_result[i][0]\n",
    "                                )[0][0]\n",
    "                                vaild_result[row_index] = cur_result[i][1]\n",
    "                        result.extend(vaild_result.astype(float))\n",
    "                    else:\n",
    "                        vaild_result = cur_result[:, -1].astype(float)\n",
    "                        vaild_result[np.isnan(vaild_result)] = 0\n",
    "                        result.extend(vaild_result)\n",
    "                else:\n",
    "                    vaild_result = cur_result[:, -1].astype(float)\n",
    "                    vaild_result[np.isnan(vaild_result)] = 0\n",
    "                    result.extend(vaild_result)\n",
    "        result_dict[mode] = result\n",
    "    result_dict_full[dataset_name] = result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import collections as matcoll\n",
    "import math\n",
    "\n",
    "dataset_name_ls = [\n",
    "    \"adult\",\n",
    "    \"lung_cancer\",\n",
    "    \"cylinder-bands\",\n",
    "    \"diabetes\",\n",
    "    \"contraceptive\",\n",
    "    \"blood-transfusion-service-center\",\n",
    "    \"steel-plates-fault\",\n",
    "    \"jungle_chess_2pcs_raw_endgame_complete\",\n",
    "    \"telco_customer_churn\",\n",
    "    \"bank-marketing\",\n",
    "    \"PhishingWebsites\",\n",
    "    \"hotel_bookings\",\n",
    "]\n",
    "dt_name_ls_full = [\n",
    "    \"Adult\",\n",
    "    \"Lung Cancer\",\n",
    "    \"Cylinder Bands\",\n",
    "    \"Diabetes\",\n",
    "    \"Contraceptive Method\",\n",
    "    \"Blood Trans. Serv. Ctr.\",\n",
    "    \"Steel Plates Faults\",\n",
    "    \"Jungle Chess\",\n",
    "    \"Telco Customer Churn\",\n",
    "    \"Bank Marketing\",\n",
    "    \"Phishing Websites\",\n",
    "    \"Hotel Reservations\",\n",
    "]\n",
    "dt_name_dict = dict(zip(dataset_name_ls, dt_name_ls_full))\n",
    "\n",
    "mode_ls = [\"ignore\", \"rectify\"]\n",
    "sql_ls = [\"q1.sql\", \"q2.sql\", \"q3.sql\", \"q4.sql\"]\n",
    "\n",
    "result_dict_full = {}\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2, ncols=6, figsize=(13, 3), subplot_kw={\"xticks\": [], \"yticks\": []}\n",
    ")\n",
    "plt.subplots_adjust(wspace=-0.5)\n",
    "error_ls_ignore = []\n",
    "error_ls_rectify = []\n",
    "\n",
    "dataset_idx = 0\n",
    "for ax, dataset_name in zip(axs.flat, dataset_name_ls):\n",
    "    labels = [\"#1\", \"#2\", \"#3\", \"#4\"]\n",
    "\n",
    "    results_ls = {\"ignore\": [], \"rectify\": []}\n",
    "\n",
    "    with open(f\"../example_query/{dataset_name}/rq2_result.json\", \"r\") as f:\n",
    "        rq2_result = json.load(f)\n",
    "\n",
    "    for mode in mode_ls:\n",
    "        for sql_name in sql_ls:\n",
    "            gt_result = np.array(rq2_result[sql_name + \",gt\"])\n",
    "            cur_result = np.array(rq2_result[sql_name + \",\" + mode])\n",
    "            if gt_result.shape[1] > 1:\n",
    "                if not np.array_equal(gt_result[:, 0], cur_result[:, 0]):\n",
    "                    print(\"error\")\n",
    "                    print(dataset_name, mode, sql_name)\n",
    "                    vaild_result = np.zeros(gt_result.shape[0])\n",
    "                    for i in range(len(cur_result)):\n",
    "                        invalid_idx = 0\n",
    "                        if cur_result[i][0] in gt_result[:, 0]:\n",
    "                            row_index = np.where(gt_result[:, 0] == cur_result[i][0])[\n",
    "                                0\n",
    "                            ][0]\n",
    "                            vaild_result[row_index] = cur_result[i][1]\n",
    "                    result.extend(vaild_result.astype(float))\n",
    "                else:\n",
    "                    vaild_result = cur_result[:, -1].astype(float)\n",
    "                    vaild_result[np.isnan(vaild_result)] = 0\n",
    "            else:\n",
    "                vaild_result = cur_result[:, -1].astype(float)\n",
    "                vaild_result[np.isnan(vaild_result)] = 0\n",
    "            l1_error = np.linalg.norm(\n",
    "                gt_result[:, -1].astype(float) - vaild_result, 1\n",
    "            ) / np.linalg.norm(gt_result[:, -1].astype(float), 1)\n",
    "            results_ls[mode].append(l1_error)\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "\n",
    "    error_ls_ignore.extend(results_ls[\"ignore\"])\n",
    "    error_ls_rectify.extend(results_ls[\"rectify\"])\n",
    "\n",
    "    lines = []\n",
    "    min_error = np.min([np.min(results_ls[\"ignore\"]), np.min(results_ls[\"rectify\"])])\n",
    "    max_error = np.max([np.max(results_ls[\"ignore\"]), np.max(results_ls[\"rectify\"])])\n",
    "    normalized_ignore = (results_ls[\"ignore\"] - min_error) / (max_error - min_error)\n",
    "    normalized_rectify = (results_ls[\"rectify\"] - min_error) / (max_error - min_error)\n",
    "    for idx, label in enumerate(labels):\n",
    "        lines.append([(idx, normalized_ignore[idx]), (idx, normalized_rectify[idx])])\n",
    "    linecoll = matcoll.LineCollection(lines, colors=\"black\", linewidths=1)\n",
    "    ax.add_collection(linecoll)\n",
    "    ax.set_title(dt_name_dict[dataset_name], fontsize=11.3)\n",
    "\n",
    "    ax.scatter(\n",
    "        x, normalized_ignore, marker=\"o\", color=\"red\", label=\"w/o Guardrail\", s=11\n",
    "    )\n",
    "    ax.scatter(\n",
    "        x, normalized_rectify, marker=\"*\", color=\"blue\", label=\"w/ Guardrail\", s=11\n",
    "    )\n",
    "\n",
    "    ax.set_xticks(x, labels, size=9)\n",
    "    if dataset_idx % 6 == 0:\n",
    "        ax.set_yticks([0, 1])\n",
    "\n",
    "    ax.tick_params(axis=\"y\", labelsize=10)\n",
    "    dataset_idx += 1\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(\n",
    "    handles, labels, loc=\"center\", bbox_to_anchor=(0.5, -0.05), ncol=2, fontsize=11\n",
    ")\n",
    "fig.text(\n",
    "    -0.005,\n",
    "    0.5,\n",
    "    \"Relative Error (Normalized)\",\n",
    "    va=\"center\",\n",
    "    rotation=\"vertical\",\n",
    "    fontsize=11.2,\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save as pdf\n",
    "fig.savefig(\"rq2_error_handling_scheme.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "reduction_error_ls = (np.array(error_ls_ignore) - np.array(error_ls_rectify)) / (\n",
    "    np.array(error_ls_ignore) + 0.0000000000000001\n",
    ")\n",
    "print(np.mean(reduction_error_ls), np.std(reduction_error_ls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisyfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
